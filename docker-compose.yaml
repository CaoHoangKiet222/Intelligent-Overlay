version: "3.9"

services:
  ollama:
    image: ollama/ollama:latest
    container_name: ai_core_ollama
    environment:
      OLLAMA_HOST: 0.0.0.0:11434
      OLLAMA_NUM_GPU: ${OLLAMA_NUM_GPU:-}
      OLLAMA_GPU_ENABLED: ${OLLAMA_GPU_ENABLED:-true}
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - ai_core_network
    # Uncomment below for AMD/ROCm GPU support on Linux
    # devices:
    #   - /dev/dri:/dev/dri
    # For Apple Silicon (macOS), run Ollama natively instead of Docker
    # to use Metal GPU acceleration
    # healthcheck:
    #   test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
    #   interval: 10s
    #   timeout: 5s
    #   retries: 5

  ollama-init:
    image: curlimages/curl:latest
    container_name: ai_core_ollama_init
    depends_on:
      - ollama
    environment:
      OLLAMA_HOST: http://ollama:11434
    networks:
      - ai_core_network
    volumes:
      - ./scripts/ollama-init.sh:/ollama-init.sh:ro
    entrypoint: ["/bin/sh", "/ollama-init.sh"]
    restart: "no"

  postgres:
    image: pgvector/pgvector:pg16
    container_name: ai_core_postgres
    environment:
      POSTGRES_USER: ${DB_USER:-ai}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-ai}
      POSTGRES_DB: ${DB_NAME:-ai_core}
    ports:
      - "${DB_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - ai_core_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-ai} -d ${DB_NAME:-ai_core}"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: ai_core_redis
    ports:
      - "${REDIS_PORT:-6379}:6379"
    networks:
      - ai_core_network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: ai_core_zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - ai_core_network
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  broker:
    image: confluentinc/cp-kafka:7.5.0
    container_name: ai_core_kafka
    ports:
      - "${KAFKA_PORT:-9092}:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: >
        PLAINTEXT://host.docker.internal:9092,
        PLAINTEXT_INTERNAL://broker:29092

      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    networks:
      - ai_core_network
    healthcheck:
      test:
        [
          "CMD",
          "kafka-broker-api-versions",
          "--bootstrap-server",
          "localhost:9092",
        ]
      interval: 10s
      timeout: 10s
      retries: 10

  minio:
    image: minio/minio:latest
    container_name: ai_core_minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${S3_ACCESS_KEY:-minioadmin}
      MINIO_ROOT_PASSWORD: ${S3_SECRET_KEY:-minioadmin}
    ports:
      - "${S3_PORT:-9000}:9000"
      - "${S3_CONSOLE_PORT:-9001}:9001"
    volumes:
      - minio_data:/data
    networks:
      - ai_core_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 5

  ray-head:
    image: rayproject/ray:2.35.0-py311
    platform: linux/amd64
    shm_size: "6gb"
    container_name: ai_core_ray_head
    command: >
      bash -lc "ray start --head --dashboard-host=0.0.0.0 --port=6380 --dashboard-port=8265 --disable-usage-stats --include-dashboard=true && tail -f /dev/null"
    ports:
      - "8265:8265"
      - "6380:6380"
    networks:
      - ai_core_network
    healthcheck:
      test: ["CMD-SHELL", "ray status || exit 1"]
      interval: 5s
      timeout: 5s
      retries: 20

  ray-worker:
    image: rayproject/ray:2.35.0-py311
    platform: linux/amd64
    shm_size: "6gb"
    container_name: ai_core_ray_worker
    depends_on:
      ray-head:
        condition: service_healthy
    command: bash -lc "ray start --address=ray-head:6380 --disable-usage-stats && tail -f /dev/null"
    networks:
      - ai_core_network

  model-adapter:
    build:
      context: ./ai-core
    container_name: ai_core_model_adapter
    environment:
      PORT: 8000
      DB_DSN: ${DB_DSN:-postgresql+psycopg://ai:ai@postgres:5432/ai_core}
      REDIS_URL: ${REDIS_URL:-redis://redis:6379/0}
      S3_ENDPOINT: ${S3_ENDPOINT:-http://minio:9000}
      S3_ACCESS_KEY: ${S3_ACCESS_KEY:-minioadmin}
      S3_SECRET_KEY: ${S3_SECRET_KEY:-minioadmin}
      PROVIDER_KEYS: ${PROVIDER_KEYS:-{}}
      OLLAMA_BASE_URL: ${OLLAMA_BASE_URL:-http://ollama:11434/api}
      OLLAMA_GENERATION_MODEL: ${OLLAMA_GENERATION_MODEL:-phi3:mini}
      OLLAMA_EMBEDDING_MODEL: ${OLLAMA_EMBEDDING_MODEL:-qwen3-embedding:0.6b}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
      ollama:
        condition: service_healthy
    ports:
      - "8081:8000"
    networks:
      - ai_core_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
      interval: 10s
      timeout: 5s
      retries: 5

  prompt-service:
    build:
      context: ./ai-core
    container_name: ai_core_prompt_service
    environment:
      PORT: 8000
      DB_DSN: ${DB_DSN:-postgresql+psycopg://ai:ai@postgres:5432/ai_core}
    depends_on:
      postgres:
        condition: service_healthy
    ports:
      - "8082:8000"
    networks:
      - ai_core_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
      interval: 10s
      timeout: 5s
      retries: 5

  retrieval-service:
    build:
      context: ./ai-core
    container_name: ai_core_retrieval_service
    environment:
      PORT: 8000
      DB_DSN: ${DB_DSN:-postgresql+psycopg://ai:ai@postgres:5432/ai_core}
    depends_on:
      postgres:
        condition: service_healthy
    ports:
      - "8083:8000"
    networks:
      - ai_core_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
      interval: 10s
      timeout: 5s
      retries: 5

  agent-service:
    build:
      context: ./ai-core
    container_name: ai_core_agent_service
    environment:
      PORT: 8000
      REDIS_URL: ${REDIS_URL:-redis://redis:6379/0}
      RAY_ADDRESS: ray-head:6379
    depends_on:
      redis:
        condition: service_healthy
      ray-head:
        condition: service_healthy
    ports:
      - "8084:8000"
    networks:
      - ai_core_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
      interval: 10s
      timeout: 5s
      retries: 5

  orchestrator:
    build:
      context: ./ai-core
    container_name: ai_core_orchestrator
    environment:
      PORT: 8000
      RAY_ADDRESS: ray-head:6380
      REDIS_URL: ${REDIS_URL:-redis://redis:6379/0}
      KAFKA_BOOTSTRAP: ${KAFKA_BOOTSTRAP:-broker:9092}
      KAFKA_GROUP: ${KAFKA_GROUP:-aicore-orchestrator}
      TOPIC_TASKS: ${TOPIC_TASKS:-analysis.tasks}
      TOPIC_DLQ: ${TOPIC_DLQ:-analysis.dlq}
      DATABASE_URL: ${DATABASE_URL:-postgresql+asyncpg://ai:ai@postgres:5432/ai_core}
      MODEL_ADAPTER_BASE_URL: ${MODEL_ADAPTER_BASE_URL:-http://model-adapter:8000}
      PROMPT_SERVICE_BASE_URL: ${PROMPT_SERVICE_BASE_URL:-http://prompt-service:8000}
    depends_on:
      redis:
        condition: service_healthy
      ray-head:
        condition: service_healthy
      postgres:
        condition: service_healthy
      broker:
        condition: service_healthy
    ports:
      - "8085:8000"
    networks:
      - ai_core_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
      interval: 10s
      timeout: 5s
      retries: 5

  demo-api:
    build:
      context: ./ai-core
    container_name: ai_core_demo_api
    environment:
      PORT: 8000
      MODEL_ADAPTER_BASE_URL: ${MODEL_ADAPTER_BASE_URL:-http://model-adapter:8000}
      PROMPT_SERVICE_BASE_URL: ${PROMPT_SERVICE_BASE_URL:-http://prompt-service:8000}
      RETRIEVAL_SERVICE_BASE_URL: ${RETRIEVAL_SERVICE_BASE_URL:-http://retrieval-service:8000}
    depends_on:
      prompt-service:
        condition: service_healthy
      retrieval-service:
        condition: service_healthy
      model-adapter:
        condition: service_healthy
    ports:
      - "8090:8000"
    networks:
      - ai_core_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  postgres_data:
  minio_data:
  ollama_data:

networks:
  ai_core_network:
    driver: bridge
